---
title: "Ciência de Dados II"
output:
  html_document:
    df_print: paged
knit: (function(input_file, encoding) { out_dir <- 'docs'; rmarkdown::render(input_file,
  # encoding=encoding, output_file=file.path(dirname(input_file), out_dir, 'supervisionado.html'))})
---

## Classificando dígitos

Um experimento interessante é a tarefa de classificar dígitos utilizando o algoritmo de Redes Neurais Artificiais. Para isso precisamos relizar os experimentos em duas fases: (1) treinar a rede para reconhecer os dígitos e (2) utilizá-la para classificar novos dígitos. Para isso precisamos carregar as blbiotecas tensorflow e keras:  

```{r}
if(!require('tensorflow')) {
  install.packages('tensorflow')
}

require('tensorflow')
```

```{r}
if(!require('keras')) {
  install.packages('keras')
}

require('keras')
```

A base de dados de dígitos se chama MNIST e pode ser carregada com a função dataset_mnist. Ela contém 60000 amostras dos dígitos 0 até 9. Cada dígito é uma imagem de 28 x 28 pixels. 

```{r}
mnist = dataset_mnist()
```

A função show_digit recebe um dígito na forma de uma matriz 28 x 28 e imprime o dígito na forma de imagem. 

```{r}
show_digit <- function(numero) {
  image(numero[1:28,28:1])
}
```

Podemos utilizar a função show_digit para plotar uma amostra de todos os dígitos presentes na base de dados: 

```{r}
par(mfrow=c(2,5))
plot = lapply(0:9, function(i) {
  aux = mnist$train$x[mnist$train$y == i,,][1,,]
  show_digit(t(aux))
})
```

Normalizando os dados de treinamento e teste:

```{r}
mnist$train$x <- mnist$train$x/255
mnist$test$x <- mnist$test$x/255
```

Construindo uma Rede Neural Artificial usando Keras. Essa rede é composta de uma camanda de entrada flatten (achatada de 28 x 28 neurônios), uma camada oculta dense (128 neurônios com função de ativação linear) e uma camada de saída dense (10 neurônios com função de ativação exponencial normalizada) 

```{r}
modelo = keras_model_sequential() %>% 
  layer_flatten(input_shape = c(28, 28)) %>% 
  layer_dense(units = 128, activation = "relu") %>% 
  layer_dense(10, activation = "softmax")
```

Informações sobre a Rede Neural Artificial:

```{r}
summary(modelo)
```

Ainda precisamos definir o algoritmo de treinamento, a função de avaliação e a medida de desempenho que vamos utilizar. Podemos fazer isso com a função compile:

```{r}
modelo %>% 
  compile(
    loss = "sparse_categorical_crossentropy",
    optimizer = "adam",
    metrics = "accuracy"
  )
```

Agora podemos treinar a rede:

```{r}
historico = modelo %>% 
  fit(
    x = mnist$train$x, y = mnist$train$y,
    epochs = 10,
    validation_split = 0.3,
    verbose = 2
  )
```

É interessante medir o erro e o desempenho da rede ao longo das épocas no conjunto de treinamento e validação.

```{r}
plot(historico)
```

Agora que sabemos que a rede aprendeu a reconhecer dígitos, podemos verificar seu desempenho no conjunto de teste. Para isso precisamos aplicar essas amostras nunca antes vistas na entrada da rede e obter os valores de saída: 

```{r}
predicao <- predict(modelo, mnist$test$x)
head(predicao)
```

Cada neurônio de saída da rede irá retornar um valor. Aquele neurônio com maior valor deve indicar a classe com maior proababilidade:

```{r}
predicao = apply(predicao, 1, which.max)
predicao[1:6]
```

Calculando o desempenho da rede no conjunto de teste:

```{r}
matriz = table(mnist$test$y, predicao)
acuracia = sum(diag(matriz))/sum(matriz)
cat('A acurácia do modelo no conjunto de teste eh:', acuracia)
```
